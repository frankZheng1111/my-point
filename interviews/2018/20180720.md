# golang-20180720(17 * 20)

# 索引
- [(golang)关于context包的理解?](##golang关于context包的理解用于哪些场景-用途)
- [(golang)为什么gin的路由性能好](#golang为什么gin的路由性能好)
- [(golang)golang的GC算法](#golanggolang的GC算法)
- [(golang)连接池的实现原理](#golang连接池的实现原理)
- [(redis)redis不同数据类型底层数据实现](#redisredis不同数据类型底层数据实现)
- [(redis)redis的常用命令时间复杂度](#redisredis的常用命令时间复杂度)
- [(redis)redis使用过程中遇到哪些瓶颈](#redisredis使用过程中遇到哪些瓶颈)
- [(redis)redis高可用方案](#redisredis高可用方案)
- [(redis)redis为何被设计成单线程?](#redisredis为何被设计成单线程)
- [(微服务)golang有哪些rpc框架](#微服务golang有哪些rpc框架)
- [(微服务)微服务拆分要坚持哪些原则, 要做到什么度](#微服务微服务拆分要坚持哪些原则-要做到什么度)
- [(网络通信)关于http协议](#网络通信关于http协议)
- [(网络通信)如何理解TCP三次握手和四次挥手的状态转移](#网络通信如何理解tcp三次握手和四次挥手的状态转移)
- [(网络通信)分析并解决server日志出现许多CLOSE-WAIT的情况](#网络通信分析并解决server日志出现许多close-wait的情况)
- [(网络通信)分析并解决server日志出现许多TIME-WAIT的情况](#网络通信分析并解决server日志出现许多time-wait的情况)
- [(mysql)关于innodb存储引擎](#mysql关于innodb存储引擎)
- [(mysql)一句sql语句的执行流程什么样](#mysql一句sql语句的执行流程什么样)
- [(mysql)sql解析顺序](#mysqlsql解析顺序)
- [(mysql)sql索引命中](#mysqlsql索引命中)
- [(mysql)线上每秒1000插入的表，扩展一个字段, 此时会发生什么?](#mysql线上每秒1000插入的表扩展一个字段-此时会发生什么)
- [(mysql)一张超大的表加字段该怎么加](#mysql一张超大的表加字段该怎么加)
- [(mysql)innodb下哪些操作会触发锁](#mysqlinnodb下哪些操作会触发锁)
- [(mysql)关于innodb存储引擎](mysql关于innodb存储引擎)
- [(其他)如何诊断一个慢的服务](#其他如何诊断一个慢的服务)

## 关于golang

### (golang)关于context包的理解(用于哪些场景, 用途)
- [直接结论](http://www.nljb.net/default/Golang%E4%B9%8BContext%E7%9A%84%E4%BD%BF%E7%94%A8/): 解决不能从外部杀死停止goroutine(让它自己结束), 是channel＋select的优化版, 解决了一个请多个派生goroutine实现: 有效期，中止线程树，传递请求全局变量。(通常ctx作为第一个参数传入)。
- [详细内容](https://deepzz.com/post/golang-context-package-notes.html): 例如Go实现httServer中，一个请求对应一个goroutine去处理。请求处理函数若启动启动额外goroutine(访问后端服务如数据库和RPC服务)。当一个请求被取消或超时时，所有用来处理该请求的goroutine都应该迅速退出，然后系统才能释放这些goroutine占用的资源
- 相关demo: [各类方法WithValue/Cancel/Timeout/Deadline](/golang/stdpkg/context.go), [实际场景: 监听特定接口到超时为止](/golang/socket/socketServer.go)

### (golang)为什么gin的路由性能好
- 直接结论: 路由块用了httprouter, json序列化用了jsoniter(高性能著称, 貌似from滴滴的工程师). httprouter性能好因为他是自己写的优化，没有用标准库
- [详细内容](http://www.csyangchen.com/go-http-router.html): 为什么httprouter性能好:
  - http.ServeMux: 标准库自带的URL路由, 每个路径注册到一个map(类型是map[string(即pattern)]muxentry{ handlefunc, pattern })里面, 查找时遍历map, 不支持动态路由(若要设置动态路由，仅能将静态路由最后一个字符设置为斜杠故仅支持前一段, 且自行解析参数), 并匹配最长路径(即动态路由的情况下匹配最长的一个路由, 故每次需要遍历字典，故性能慢).无法按方法分发
  - httpRouter: 相对标准库多支持了动态路由及按方法分发, 路由信息的存储结构是树状结构, 每个节点保留了其子节点的路由信息, 通过循环查找, 找到匹配(精准匹配)的遍便直接返回，故性能高于标准库(beego慢在同是树状结构未保存子节点路由信息，且使用递归遍历)

### (golang)golang的GC算法:
- 直接结论: 三色标记算法(1.8rc)
- 前置扩展([详细](http://legendtkl.com/2017/04/28/golang-gc/), [简略](https://lengzzz.com/note/gc-in-golang)): 常见的GC算法:
  - 引用计数(OC, PHP): 每个对象内部维护该对象的引用计数(有指针指向该单元时计数加1, 删除某个指向它的指针时计数减1)，引用计数为0时，自动销毁对象(销毁时其指向的其他对象计数减1)。
    - 优点: 渐进式分摊了gc成本,算法易实现, 堆不用被耗尽到某个阈值前才会触发
    - 缺点: 不能处理循环引用(后来有对应方案，例如强引用), 维护应用计数存在开销，其他: 存放对象的池不是cachefriendly的，容易cache miss影响效率
  - Mark-Sweep法(标记清除法, go<1.3, 1.3时Sweep改为并行操作): 该算法是第一种自动内存管理，基于追踪的垃圾收集算法。很古老(70年代)。变成垃圾未立刻回收，保持不可达状态，当满足时间间隔或堆的阈值。用户程序被系统挂起(STW: StopTheWorld), 从程序(堆)的根节点递归遍历所有能访问到的对象(包括对象指向的对象)并打上标记(Mark)。清除(Sweep)没有被标记的对象
    - 优点: 不用维护引用计数值
    - 缺点: 程序被整个挂起(STW)
  - 三色标记法(Tri-color marking, go1.5 & 1.6): 对象分为三个颜色(颜色代表集合)(白: GC候选对象(待处理); 灰: 不会被GC,但对白对象引用待确认(处理中) 黑色:不存在对白对象的引用(处理完成)
    - 原理:创建集合白、灰、黑。 所有对象为白色。 从根节点开始遍历所有对象(不递归, 故只有第一层对象)，遍历到的对象变为灰色。 再遍历灰对象(并变黑)，将灰对象引用的白对象变灰，重复到灰色中无任何对象 通过write-barrier检测对象有变化，重复以上操作sweep所有白色对象(清除时会stw)
    - 优点: 标记时不会stw
    - 缺点: 垃圾生成速度大于标记速度造成堆积, 且需要其他技术(write-barrier)跟踪对象引用变化
  - 分代收集(jvm .net): 依据：绝大部分对象生命周期都很短。所以按照对象的生命周期长短来进行分代(0, 1, 2)。 新对象放入0代, 当内存用量超过阈值(小)时，触发0代GC, 幸存对象放入1代,当超过阈值(中)时, 触发1代回收, 2代同理
    - 因为0代对象少，每次收集时遍历都很快(较1代快几个数量级)。只有内存消耗过大时才会触发较慢的1代和2代收集。
    - 优点: 分代收集是目前比较好的垃圾回收方式。
    - 缺点: 实现复杂
- [详细内容](http://legendtkl.com/2017/04/28/golang-gc/):
  - 何时触发GC: 在堆上分配大于32K字节对象时检测此时是否触发gc(代码:forceTrigger||memstats.heap\_live>=memstats.gc\_trigger)(强制触发(手动或每隔2分钟)or当前堆上的活跃对象大于初始化时设置的触发阈值: 默认4MB, 每次标记后会动态更新/翻倍)
  - 通过三色标记法进行GC:
    - 开始gc后: 第一次STW, 不符初始化操作, 例如启动write-barrier
    - stack scan: 从root开始遍历(全局和goroutine栈上的指针)。使该些对象变灰(灰色队列GCW每个P都有，全局也有)
    - mark: 遍历灰色对象，其引用对象变灰，自身变黑
    - marktermination: 第二次STW，根据write-barrier重新扫描全局和变变化过的goroutine的栈(1.8开始不扫描goroutine了), 结束标记, 收缩栈
    - sweep: 清除白对象(上锁), 重定义触发阈值

### (golang)连接池的实现原理
- 直接结论: 将连接句柄(什么是句柄: 句柄是个数字(长度和系统位数相同)。是一个对象的唯一Id), 存入channel中，由于缓存chan特性，获取连接时优先返回池中现存连接，若没有，则阻塞或创建新连接，将阻塞或者新建连接（在最大限制数以下）。
- 具体代码: [demo](/golang/points/genericPool.go)
- 额外扩展: 如何池化goroutine,即控制goroutine数量(通过装饰器方式改进WaitGroup，Add行为在超出连接数时被chan阻塞)

## 关于redis

### (redis)redis不同数据类型底层数据实现
- 直接结论:
  - [ZSET](http://yaronspace.cn/blog/archives/1259): hash表和skiplist(跳跃表)，前者实现set功能及O(1)查询, 后者实现有序并插入删除操作时间复杂度是O(logn)。
  - [LIST](http://redisbook.readthedocs.io/en/latest/internal-datastruct/adlist.html): 双向链表并记录头结点和尾节点
    - 压缩双链表以连续的内存空间来表示双链表，压缩双链表节省前驱和后驱指针的空间(8B)。


### (redis)redis的常用命令时间复杂度
- [直接结论](http://redisdoc.com/index.html): 根据key值查找的过程基本都是O(1)
  - HGET: 获取一个key下对象下单个键值对; O(1)
  - HGETALL: 获取一个key下对象下所有键值对; O(n) n为对象键值对数量
  - HMGET: 获取一个key下对象下部分键值对; O(n) n为给定键的数量
  - KEYS [pattern]: 返回匹配规则的key; O(n) n为redis内key的数量
  - SORT: 指定集合排序; O(N+M\*log(M))， N为总量, M为要返回的数量, 即只需排序出前M个数即可
  - SISMEMBER: 判断set中是否存在该成员; O(1), (Set也许是通过HASH实现的)
  - ZSET集合中的单个成员操作时间复杂度O(logN)


### (redis)redis使用过程中遇到哪些瓶颈
- 直接结论: 根本问题是系统io瓶颈(即硬盘读写速度不够快)，主进程 fsync()/write() 操作被阻塞。
- [详细内容](https://blog.csdn.net/u011007180/article/details/53412352): 具体的IO瓶颈
  - Q:
  - 持久化: rdb(内存快照): save命令调度rdbSave函数，会阻塞主线程的工作; AOF持久化(默认每秒调用fsync): 对性能影响小(只要不重写文件)，AOF文件会不断增大，影响Master重启恢复速度。(两者都会fork一个子进程, 这是个略耗时的操作)
  - 主从复制: 主从关联后第一次同步：Slave请求Master同步，Master先dump出rdb文件，全量传输至Slave，最后Master把缓存的命令转发给Slave。之后的同步是: Master将增量的快照实时依次发送给各个Slave(若Slave和Master断开重连会重复以上过程)。主从复制基于rdb持久化。
    - ps: 尽管Redis宣称主从复制无阻塞，但是限于磁盘io，若快照文件比较大，dump会很久(期间Master可能无法响应请求)
  - A:
  - Master尽可能不作持久化(特别是)
  - 若数据关键: 某个Slave开启AOF备份数据，策略为每秒同步一次。
  - 为了稳定性，Slave和Master最好在同一个局域网内。
  - 避免在压力较大的主库上增加从库

### (redis)redis高可用方案
- 直接结论: 使用主从(流量压力分散给从库, 同时避免单点故障), 集群(最大化利用内存, 解决木桶短板效应，避免全量存储), 哨兵(自动化在主节点挂掉时将从节点转为主节点)
- [详细内容](https://blog.csdn.net/c295477887/article/details/52487621):
  - 主从复制(replication): 持久化(AOF(记录日志操作文件), RDB(内存快照))到硬盘上，重启后不丢失数据; 主从复制解决了单点故障(即一台机器挂了或者硬盘故障其他机器依旧提供服务)
    - 配置: 从服务器的conf文件加入slaveof ip port配置即可 OR redis-server --port 6380 --slaveof 主服务IP 主服务端口
  - 哨兵机制(redis-sentinel): 哨兵的作用就是监控Redis系统的运行状况包括(监控主从数据库; 主数据库出现故障时自动将从数据库转换为主数据库)
    - 配置: redis-sentinel sentinel.conf([sentinel monitor 主服务名 主服务ip 端口 需要多少个sentinel判断故障](https://blog.csdn.net/u010648555/article/details/79430105))
  - 集群模式: 分布式存储。即每台redis存储不同的内容。集群至少需要3主3从，且每个实例使用不同的配置文件，主从不用配置，集群会自己选。大家会给对应的从投票，把从立为主，若没有从数据库可以恢复则redis集群就down了
    - 启动: redis-cli -c -p
- 扩展: 主从和集群的区别是前者存着全量数据, 后者存着部分数据

### (redis)redis为何被设计成单线程
- [直接结论](https://blog.csdn.net/qqqqq1993qqqqq/article/details/77538202): 因为CPU不是Redis瓶颈。Redis的瓶颈最有可能是机器内存或者网络带宽。（官方FAQ）单线程容易实现, 且CPU也不能逾越网络io瓶颈，故使用单线程

## 关于微服务

### (微服务)golang有哪些rpc框架
- [直接结论](https://scguoi.github.io/DivisionByZero/2016/11/15/GO%E8%AF%AD%E8%A8%80RPC%E6%96%B9%E6%A1%88%E8%B0%83%E7%A0%94.html): 原生rpc, rpcx, thrift, grpc 性能降序排列，后两个支持跨语言

### (微服务)微服务拆分要根据哪些设计原则, 要做到什么度
- 直接结论:
  - [设计原则](https://juejin.im/entry/59b292e9f265da06633cf89a): AFK原则(按服务功能拆, 水平扩展, 类似数据分区的集群分区), 前后分离(不使用传统模板, 物理分离部署), 无状态(通过其他分布式存储服务存储状态), restful通信风格
  - 拆分粒度: 原则上做到高内聚低耦合, 可以做到独立部署, 且是一个团队可以承载的量, 具体粒度粗细各有优缺点
    - 粒度越细: 扩容缩容更加精准，提高资源利用率, 代码的耦合性减少, 因服务集群化，故单个节点挂掉影响小
    - 粗粒度拆分: 定位问题方便, 服务之间的依赖减少, 监控方便，分布式事务减少

## 关于网络通信

### (网络通信)关于http协议
- [详细内容](http://www.ruanyifeng.com/blog/2016/08/http.html):
  - HTTP0.9(1991): 只有GET请求;只能返回HTML格式;服务器发送完毕，就关闭TCP连接。
  ```
  GET /index.html
  ```
  - HTTP1.0(1996): 新引入POST,HEAD请求; 其中一个链接仅处理一个请求(用非标准字段: Connection: keep-alive解决这问题)
    - 请求: 第一行尾部添加协议版本(HTTP/1.0)。后面就是多行头信息，描述客户端的情况。
    ```
    GET / HTTP/1.0
    User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5)
    Accept: */* //表示客户端能解析的格式
    Accept-Encoding: gzip, deflate // 客户端接受的压缩格式
    ```

    - 响应: 格式是"头信息+空行(\r\n)+数据"。第一行是"协议版本+状态码(statusCode)+状态描述"。其中头信息必须是ASCII码，后面数据任意格式
    ```
    HTTP/1.0 200 OK 
    Content-Type: text/plain // 返回的数据格式
    Content-Length: 137582
    Expires: Thu, 05 Dec 1997 16:00:00 GMT
    Content-Encoding: gzip // 数据压缩的格式
    Last-Modified: Wed, 5 August 1996 15:55:28 GMT
    Server: Apache 0.84

    <html>
    <body>Hello World</body>
    </html>
    ```
  - HTTP1.1(1997): 新引入 PUT、PATCH、HEAD、 OPTIONS、DELETE
    - 标准化了Connection: keep-alive(客户端Connection: close后服务端关闭链接)
    - 管道机制: 以前(req1, resp1, req2, resp2), 现在(req1,req2,resp1,resp2), 用Content-Length区分单个回应。缺点: 若前面的请求慢容易引起管道堵塞
    - 分块传输: header头中有Transfer-Encoding: chunked表示长度未知的数据块来传输，遇到大小为0的快表示数据完了
  - HTTP2: 头和数据体都是二进制; 支持服务器推送; 管道不用按顺序排队(可以先返回已经请求中已经处理好的部分, 拆分开来的部分用数据流ID作区分), 头信息可以压缩，相同重复的字段(User-Agent:,Cookie)缓存在C/S各自的头信息表中.
  
### (网络通信)如何理解TCP三次握手和四次挥手的状态转移
- 详细内容([参考1](https://www.jianshu.com/p/a4beee06220c), [参考2](https://www.jianshu.com/p/a4beee06220c)):
  - *三次握手*([ClientStatus, ServerStatus], SYN,FIN,ACK=1为标志位, 下面描述中若没有显示指定标志位时默认为0, ack为ack number):
    - 服务端开始监听端口[CLOSED, CLOSED => LISTEN]
    - (**第一次握手**)客户端发送(SYN=1, seq=序号c1), [CLOSED => SYN-SENT, LISTEN]
    - (**第二次握手**)服务端收到建立连接的请求(报文段?), 返回响应(SYN=1, ACK=1, seq=序号s1, ack=序号c1+1), [SYN-SENT, LISTEN => SYN-RCVD]
    - (**第三次握手**)客户端收到响应的请求(报文段?), 校验ACK和ack后, 返回(ACK=1, seq=序号c1+1, ack=序号s1+1)并开始建立连接, [SYN-SENT => ESTABLISHED, SYN-RCVD]
    - 服务端收到并校验ACK和ack后建立连接, [ESTABLISHED, SYN-RCVD => ESTABLISHED]
  - *四次挥手*([主动方Status, 被动方Status], RST是连接异常, 收到这个的话发请求一方会进入CLOSED状态):
    - 双方建立连接中[ESTABLISHED, ESTABLISHED]
    - (**第一次挥手**)主动方发送(FIN=1, seq=序号c1), 表示不会再发送新的数据, [ESTABLISHED => FIN-WAIT1, ESTABLISHED]
    - (**第二次挥手**)被动方收到断开连接的请求(报文段?), 返回响应(ACK=1, seq=序号s1, ack=序号c1+1)并继续发送剩余数据, [FIN-WAIT1, ESTABLISHED => CLOSED-WAIT]
    - 主动方收到响应的请求(报文段?), 校验ACK和ack后, 等待后续剩余数据[FIN-WAIT1 => FIN-WAIT2, CLOSED-WAIT]
    - (**第三次挥手**)被动方发送完剩余数据后发送响应的请求(报文段?), 返回(FIN=1, ACK=1, seq=序号s2, ack=序号c1+1), [FIN-WAIT2, CLOSED-WAIT => LAST-ACK]
    - (**第四次挥手**)主动方收到响应的请求(报文段?), 校验ACK和ack后, 返回(ACK=1, seq=序号c1+1, ack=序号s2+1)告诉被动方可以关闭链接, [FIN-WAIT2 => TIME-WAIT, LAST-ACK]
    - 被动方收到响应的请求(报文段?), 校验ACK和ack后断开卡连接 [TIME-WAIT, LAST-ACK => CLOSED]。
      - PS: 若LAST-ACK未收到ACK, 会重试发送FIN(即第三次挥手), 直到超时为止
    - TIME-WAIT持续2MSL, 后若未再收到被动方的新FIN, 关闭链接(收到的话则再发送个ACK, 但不会重置TIME-WAIT时间)
      - MSL: Maximum Segment Lifetime,译为“报文最大生存时间”，他是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。RFC793中为2分钟，实际常用30秒or1分钟or2分钟

### (网络通信)分析并解决server日志出现许多CLOSE-WAIT的情况
- 最终原因: server端作为断开连接挥手过程的被动方, 收到断开连接请求后一直未发出FIN报文, 导致CLOSE-WAIT堆积
- 解决方案:
  - 排查是否程序本身是否有操作阻塞后续流程(例如服务长时间未响应则客户端主动断开连接, 服务端发出ACK后因为代码阻塞导致未能发出FIN报文, 可能CPU占用过高)
  - 牺牲部分TCP可靠性: 修改系统，系统默认超时为7200(tcp\_keepalive\_time)秒, 超时后发动tcp\_keepalive\_probes(默认9)次探测, 间隔tcp\_keepalive\_intvl(默认75)秒. 之后才会作为默认连接关闭

### (网络通信)分析并解决server日志出现许多TIME-WAIT的情况
- 最终原因: server端作为断开连接挥手过程的主动方, 最后一次挥手后会保持2MSL的TIME-WAIT, 导致TIME-WAIT堆积
- 解决方案: 日常HTTP请求API，server响应后主动关闭连接，于是TIME-WAIT便留在了服务端。若客户端可控，服务端打开KeepAlive，而让客户端主动关闭连接。
  - 牺牲部分TCP可靠性: 修改这些参数: 
    - tcp\_tw\_recycle: 在3.5RTO(recovery time objective, 200ms~120s不等)后回收的TIME-WAIT数量)
    - tcp\_tw\_reuse: 复用TIME-WAIT连接。当创建新连接的时候，尽可能的话会考虑相应TIME-WAIT连接, 仅对请求发起方有效(server端的话例如查询sql), 需激活tcpi\_timestamps
    - tcp\_max\_tw\_buckets：限制TIME-WAIT的数量, 系统会删除多余的TIME-WAIT连接

## 关于mysql

### (mysql)一句sql语句的执行流程什么样
- [详细内容](https://www.cnblogs.com/annsshadow/p/5037667.html):
  - 1.连接
  - 1.1客户端发起Query请求，监听客户端的‘连接管理模块’接收req
  - 1.2req转发至‘连接进/线程模块’
  - 1.3调用‘用户模块’检查授权
  - 1.4鉴权后,‘连接进/线程模块’从‘线程连接池’中取出空闲&被缓存的连接线程并对接客户端，若失败则创建新连接
  - 2.处理
  - 2.1先查缓存，Query语句是否完全匹配，再鉴权，都成功则直接取数据返回
  - 2.2上一步失败则转交给‘命令解析器’，分析后生成解析树
  - 2.3接下来是预处理阶段，处理解析器无法解决的语义，检查权限等，生成新的解析树
  - 2.4再转交给对应的模块处理
  - 2.5如果是SELECT查询还会经由‘查询优化器’做大量的优化，生成执行计划
  - 2.6模块收到请求后，通过‘访问控制模块’检查所连接的用户是否有访问目标表和目标字段的权限
  - 2.7有则调用‘表管理模块’，先是查看table cache中是否存在，有则直接对应的表和获取锁，否则重新打开表文件
  - 2.8根据表的meta数据，获取表的存储引擎类型等信息，通过接口调用对应的存储引擎处理
  - 2.9上述过程中产生数据变化的时候，若打开日志功能，则会记录到相应二进制日志文件中
  - 3.结果
  - 3.1Query完成后，结果集(或相应的状态标识，如成功/失败)返回‘连接进/线程模块’
  - 3.2‘连接进/线程模块’进行后续的清理工作，并继续等待请求或断开与客户端的连接

### (mysql)sql解析顺序
- 直接结论:
  ```sql
  FROM <left_table>
  ON <join_condition>
  <join_type> JOIN <right_table>
  WHERE <where_condition>
  GROUP BY <group_by_list>
  HAVING <having_condition>
  SELECT
  DISTINCT <select_list>
  ORDER BY <order_by_condition>
  LIMIT <limit_number>
  ```
- 补充: where条件会在B-treeIndex这部分进行索引匹配，如果命中索引，就会定位到指定的table records位置。如果没有命中，则只能采用全部扫描的方式。
### (mysql)sql索引命中
- 直接结论:
  - [联合索引](https://www.cnblogs.com/wujf/p/9176840.html): mysql查询优化器的只用一个索引, 故多列条件的情况下联合索引优于单列索引, 联合索引从左边开始命中(必须and连接,即abc,ab,a都可以命中索引[a,b,c])
  - [索引命中](https://blog.csdn.net/lixingying567/article/details/73505943): \<\>,!= 两个运算符不走索引, or的话必须两个字段都有索引(否则建议使用union)
  - [explain的字段意义](https://blog.csdn.net/lixingying567/article/details/73505943): 
    - select\_type: 查询类型(SIMPLE:不使用表连接或子查询简单查询。PRIMARY:主查询,外层的查询。UNION:第二个或者后面的查询。SUBQUERY:子查询中的第一个select)
    - table: 输出结果的表
    - type: 表示MySql在表中找到所需行的方式，或者叫访问类型。常见的类型：ALL(全表扫描); index(遍历整个索引); range(索引范围扫描: >, <,between in 等); ref(非唯一索引扫描); eq\_ref(用于多表连接 主建/唯一健作为关联条件); const/system(唯一索引字段=) NULL(没有用到索引: 如limit0)
    - possible\_keys: 可能使用的索引列表.
    - key: 实现执行使用索引列表
    - key\_len: 索引的长度
    - ref: 显示使用哪个列或常数与key一起从表中选择行。
    - row: 执行查询的行数，简单且重要，数值越大越不好，说明没有用好索引
    - filtered:
    - Extra: 该列包含MySQL解决查询的详细信息。

### (mysql)线上每秒1000插入的表，扩展一个字段, 此时会发生什么?
- [详细内容](https://www.cnblogs.com/wangtao_20/p/3504395.html)
  - 对表加只读锁(写操作会pending)
  - 复制原表结构(中间表)
  - 修改中间表结构
  - 把原表数据导入中间表(数据量越大时间越大)，完成后锁定中间表，并删除原表
  - rename中间表为原表
  - 刷新数据字典(类似数据库名,表名,表状态等源信息)，并释放锁

### (mysql)一张超大的表加字段该怎么加
- [直接结论](https://www.cnblogs.com/wangtao_20/p/3504395.html):
  - 方案1: 逐个停掉mysql服务修改结构(时间长, 需要全部更新同步完才能推送新代码)
  - 方案2: online-schema-change 工具
  - [方案3](https://blog.tanteng.me/2017/01/mysql-alter-table-big-data/): 模仿原生修改结构的流程，一开始不锁表，第一次迁移数据, 再反复做增量迁移，在增量内容少的情况下是锁边完成后续流程
  - [方案4](https://blog.tanteng.me/2017/01/mysql-alter-table-big-data/): 修改从表结构然后主从切换

### (mysql)innodb下哪些操作会触发锁
  - 直接结论:
    - 操作事务触行锁(锁索引, 即相关操作未命中索引的情况下使用的是表锁)
    - 主动锁表(lock tables [表名, read/write...]; unlock tables;)
    - 修改表结构触发只读表锁

### (mysql)关于innodb存储引擎
  - [前置条件1](http://blog.jobbole.com/111757/): 关于B树:
    - B-Tree(念作B树, mongodb 作为存储索引)为二分查找树的"矮胖版", 解决了二分查找树频繁磁盘io的问题(数据量大 => 索引大 => 无法全部加载至内存 => 逐页(页=节点)加载), m阶B树满足以下条件, 其中后两个条件保证了自平衡(相对的插入和删除操作可能会修改较多表结构)
    - 根结点至少有两个子女。
    - 每个节点都包含(m/2-1~m-1)个元素和(m/2 ~ m)个孩子(叶子节点没有)，其中 m/2 <= k <= m
    - 所有的叶子结点都位于同一层。
    - 节点中元素升序排列，其中元素正好是子节点的元素的值域分划。
  - [前置条件2](http://www.10tiao.com/html/200/201707/2655438707/1.html): 关于B+树:
    - B+Tree为B树的"改进版", 查询性能稳定(数据都在叶子节点), 并使得树更矮胖(同大小磁盘页因为只包含索引能有更多元素), 便于范围查询, 在B树的基础上符合以下额外条件:
    - 中间节点的元素不保存数据，只用来索引，所有数据都保存在叶子节点。
    - 所有叶子结点中包含全部元素，及指向对应记录的指针，叶子结点依关键字大小顺序链接。
    - 所有中间节点元素都同时存在于子节点，在子节点元素中是最大（若降序索引则是最小）元素。
  - [直接结论](https://blog.csdn.net/EveryFriDay_ShuJk/article/details/79674172):  InnoDB存储引擎支持两种索引，一种是B+树索引，一种是哈希索引。
    - InnoDB存储引擎支持哈希索引为自适应的，引擎会自行根据表的使用生成哈希索引，不能人为干预
    - B+树索引是传统意义上的索引, B+树索引并不能找到一个给定键值的具体行，能找到的只是被查找数据行所在的页(即叶子节点, 叶节点包含了完整的数据记录。这种索引叫做聚集索引)，然后数据库通过把页读入内存，再在内存中进行查找，最后得到查找数据。
      - InnoDB要求表必须有主键(MyISAM可以没有)，显式指定(考虑修改性能, 最好自增有序) => 唯一标识的数据列 => 自动生成隐藏字段(长整型)。

## 关于其他

### (其他)如何诊断一个慢的服务
- 直接结论: 分析排除干扰因素 -> 看elk分析慢服务的场景 -> 日志定位慢方法/函数 -> benchmark test 相应代码, 是否未管理好内存，是否goroutine挤压,是否竞争锁资源，是否没命中缓存
- [详细内容](https://www.zhihu.com/question/36402618):
  - 先分析用户从请求到落地经过环节，排除用户环境问题和网络问题。
  - 从web接入层开始分析，是压力大扛不住用户请求还是代码本身性能不好一直很慢（系统负载，异常日志）
  - 通过在中间件层和依赖服务中记录日志, 定位具体慢方法/函数
  - 排查是因为代码未管理好内存，是否是goroutine积压，是否没命中缓存
- [其他扩展](https://liudanking.com/arch/%E5%AE%B9%E5%99%A8%E7%8E%AF%E5%A2%83%E4%B8%8B-go-%E6%9C%8D%E5%8A%A1%E6%80%A7%E8%83%BD%E8%AF%8A%E6%96%AD%E6%96%B9%E6%A1%88%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/): 容器环境下 go 服务性能诊断方案设计与实现

go build 编译平时用那些参数
https://studygolang.com/articles/10117
